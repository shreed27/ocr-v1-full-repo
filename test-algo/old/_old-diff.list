checking files in pattern **.py*
__init__.py vs. ../old-algo/__init__.py
------------------------------------------------------------------------

adhoc-test-settings.py vs. ../old-algo/adhoc-test-settings.py
diff: ../old-algo/adhoc-test-settings.py: No such file or directory
diff: ../old-algo/adhoc-test-settings.py: No such file or directory
------------------------------------------------------------------------

answer.py vs. ../old-algo/answer.py
Differences: answer.py ../old-algo/answer.py
-rwxr-xr-x 1 Administrators None 20944 Dec 13 21:06 answer.py
-rwxr-xr-x 1 tomohara None 12634 Dec 13 22:16 ../old-algo/answer.py
3c3
< # answer.py: Defines class for representing student responses (Answer).
---
> # standard.py: Defines class for representing student responses (Answer).
6,7d5
< # Local packages
< #
10,11d7
< import wordnet
< import text
13,14d8
< # Other packages
< #
16a11
> from nltk.corpus import wordnet as wn
22,52d16
< # Utility functions
< 
< # find_most_freq_term(terms, freq_dist): Returns entry in TERMS with highest
< # frequency in FREQ_DIST (hash).
< # Note: Some of the terms might not occur in the hash.
< # EX: find_most_freq_term(['dawg', 'mouse'], {'dog':9, 'cat':7, 'mouse':11}) => 'mouse'
< # EX: find_most_freq_term(['kat', 'moose'], {'dog':9, 'cat':7, 'mouse':11}) => ''
< #
< def find_most_freq_term(terms, freq_dist_hash):
<     max_freq = -1
<     max_word = ""
<     for word in terms:
<         if (freq_dist_hash.has_key(word) and (freq_dist_hash[word] > max_freq)):
<             max_freq = freq_dist_hash[word]
<             max_word = word
<     debug_print("find_most_freq_term%s => %s" % (str((terms, freq_dist_hash, omit_terms)), max_word), level=6)
<     return max_word
< 
< # list_difference(list1, list2): Returns items in LIST1 not in LIST2.
< # EX: list_difference([3, 2, 1], [1, 2]) => [3]
< # TODO: set(list1).difference(list2)
< #
< def list_difference(list1, list2):
<     diff_list = []
<     for item1 in list1:
<         if item1 not in list2:
<             diff_list.append(item1)
<     debug_print("list_difference%s => %s" % (str((list1, list1)), str(diff_list)))
<     return (diff_list)
< 
< #------------------------------------------------------------------------
57,65d20
<     ## TODO: Constants for grading mode (level 1 for strict, 2 for moderate and 3 for loose)
<     # Note: It seems that grading mode is based more on the marking scheme than the algorithm
<     # (see ./marking0607/algo/testdata/raw/Q1/MarkingAppSystem-120314.xls).
<     # Therefore, having diffrent interpretations might be confusing (e.g., applying loose
<     # marking with moderate algorithm).
<     ## STRICT = 'strict'
<     ## LOOSE = 'loose'
<     ## MODERATE = 'moderate'
<     ## GRADING_MODES = ['strict', 'moderate', 'loose']
71d25
<         # Matching thresholds
77,99d30
<         # Settings for extensions
<         ## TEST: debug_print("setting.FUBAR = " + str(setting.FUBAR), level=5)
<         # TODO: self.apply_wordnet_expansion = setting.APPLY_WORDNET_EXPANSION
<         ## OLD: self.apply_wordnet_expansion = False
<         self.apply_synonym_expansion = False
<         self.apply_ancestor_expansion = False
<         self.max_ancestor_links = 2
<         self.use_part_of_speech = False
<         ## TODO: self.grading_mode = 'strict'
<         # Check environment overrides when debugging
<         if __debug__: 
<             ## OLD: self.apply_wordnet_expansion = getenv_boolean("APPLY_WORDNET_EXPANSION")
<             self.apply_synonym_expansion = getenv_boolean("APPLY_SYNONYM_EXPANSION")
<             self.apply_ancestor_expansion = getenv_boolean("APPLY_ANCESTOR_EXPANSION")
<             self.max_ancestor_links = getenv_number("MAX_ANCESTOR_LINKS", self.max_ancestor_links)
<             self.use_part_of_speech = getenv_boolean("USE_PART_OF_SPEECH")
<             ## TODO: self.grading_mode = getenv_text("GRADING_MODE", self.grading_mode)
<         ## TODO: assert(self.grading_mode in GRADING_MODES)
<         # TODO: Define booleans for each mode
<         ## self.loose_mode = (self.grading_mode == 'loose')
<         ## self.moderate_mode = (self.grading_mode == 'moderate')
<         ## self.strict_mode = (self.grading_mode == 'strict')
<         # Other settings
104c35
<     # Note: Changes made here should be synchronized with SentenceCal in standard.py.
---
>     # Note: Changes should be synchronized with SentenceCal in standard.py.
106,107d36
<     # TODO: See why stop words are not remove here as in CalVector from standard.py.
<     # EX: TODO
121,122d49
<             # Note: An optional part-of-speech tag prefix can be included.
<             # TODO: Isolate text preprocessing code in a separate function 
126,131d52
<             text_words_proper = list(word for word in text_words if word)
<             if self.use_part_of_speech:
<                 # Prefix each word with wordnet part-of-speech indicator (e.g., ['fast', 'car'] => ['a:fast', 'n:car'])
<                 text_words_proper = [(wordnet.get_part_of_speech(tag) + ":" + word) 
<                                      for (word, (token, tag)) in zip(text_words, part_of_speech_tagged_words) 
<                                      if word],
133c54
<                                      'StuWords': text_words_proper,
---
>                                      'StuWords': list(word for word in text_words if word),,
157d77
<     # EX: TODO
160d79
<         debug_print("Answer.CalCosDist%s" % str((ans_sentencelist, std_sen)), level=6)
163,164d81
<         apply_term_expansion = (self.apply_synonym_expansion or self.apply_ancestor_expansion)
<         std_words = std_sen['KeySVec'].keys()
168,192c85
<             for word in std_words:
<                 # OLD: q += std_sen['KeySVec'][word] * std_sen['KeySVec'][word]
<                 # OLD: s += stu_sen['StuSVec'][word] * stu_sen['StuSVec'][word]
<                 # OLD: qs += std_sen['KeySVec'][word] * stu_sen['StuSVec'][word]
< 
<                 # If a standard word doesn't occur in the student sentence, then apply term expansion
<                 # by checking for most frequent synonym and/or ancestor term that does occur.
<                 # Note: Ancestor terms might be too general, so not checked if synonym found.
<                 # Also, expansions omit standard terms to avoid counting evidence twice.
<                 # TODO: Weight synonyms less than direct and scale ancestor weight by degree or generality.
<                 stu_word = word
<                 if ((stu_sen['StuSVec'][word] == 0) and apply_term_expansion):
<                     # Check synonyms (e.g., attorney for lawyer), excluding words in standard
<                     if (self.apply_synonym_expansion):
<                         synonyms = list_difference(wordnet.get_synonyms(word), std_words)
<                         stu_word = find_most_freq_term(synonyms, stu_sen['StuSVec'])
<                         if (stu_word != word):
<                             debug_print("Using (student) synonym %s for word %s" % (stu_word, word), level=4)
<                     # Check ancestors (e.g., professional for lawyer), excluding words in standard
<                     if (self.apply_ancestor_expansion and (stu_word == word)):
<                         ancestors = list_difference(wordnet.get_ancestor_terms(word, self.max_ancestor_links), std_words)
<                         stu_word = find_most_freq_term(ancestors, stu_sen['StuSVec'], std_words)
<                         if (stu_word != word):
<                             debug_print("Using (student) ancestor term %s for word %s" % (stu_word, word), level=4)
<                 # Do componentwise update
---
>             for word in std_sen['KeySVec']:
194,196c87,88
<                 s += stu_sen['StuSVec'][stu_word] * stu_sen['StuSVec'][stu_word]
<                 qs += std_sen['KeySVec'][word] * stu_sen['StuSVec'][stu_word]
<             # Finalize cosine metric
---
>                 s += stu_sen['StuSVec'][word] * stu_sen['StuSVec'][word]
>                 qs += std_sen['KeySVec'][word] * stu_sen['StuSVec'][word]
210d101
<     # EX: TODO
212c103
<         debug_print("Answer.Mark%s" % str((std_sentencelist, std_pointlist_no, ans_sentencelist)), level=99)
---
>         debug_print("Answer.Mark(_,_,_)", level=6)
245c136
<                 ## OLD: #sen_rate = 1.0 * sen_match / math.log(len(std_senlist) + 1)
---
>                 #sen_rate = 1.0 * sen_match / math.log(len(std_senlist) + 1)
250d140
<                 # TPO: same as moderate
256,257c146,147
<             # Trace out current state (based on Xiangguandu Juzi's commented out print code)
<             debug_print("Point_No: " + str(point_no), level=5)
---
>             # Trace out current state (based on xiangguandu juzi commented out print code)
>             debug_print("Point_No: %" + str(point_no), level=5)
282c172
<     # Comparison(marks, rules): TODO
---
>     # Mark(marks, rules): TODO
376,412d265
< 
< #------------------------------------------------------------------------
< 
< # If invoked standalone, show simple hard-coded example (see tests.py for detailed examples).
< #
< if __name__ == '__main__':
<     # TODO: straighten out convoluted invocation sequence (bowl of spaghetti module inter-dependencies)
<     from standard import *
<     from markscheme import *
<     ans = Answer()
<     std = Standard()
<     key_full_text = "1 . The lawyer chased the ambulance.\n2 . The ambulance chased back.\n"
<     ## OLD: key_full_text_proper = re.sub(r"\d\.", " ", key_full_text)
<     pointlist, key_freq_dist, key_sentencelist = std.Analysis(key_full_text)
<     stu_full_text = "1 . The attorney chased the vehicle.\n2 . The vehicle chased back.\n"
<     stu_full_text_proper = re.sub(r"\d\s\.", " ", stu_full_text)
<     ## OLD: # Run through NLTK text processors, including optional part of speech tagging
<     ## OLD: key_text_words = text.preprocess(key_full_text_proper, ans.use_part_of_speech)
<     # Get frequency distribution
<     ## OLD: key_text_freq_dist = nltk.FreqDist(key_text_words_proper)
<     ## OLD: key_sentencelist = ans.SentenceAnalysis(key_full_text_proper, 
<     ## OLD: pointlist = ['P1', 'P2']
<     ##
<     ## OLD: ms = MarkScheme(pointlist)
<     ## OLD: rulelist = [r for r in ms.GetRules([("all", 10), ("only P1 or P2", 5)])]
<     scheme = [("all", 10), ("only P1 or P2", 5)]
<     print "Input:\n\nKey: %s\nScheme: %s\nStudent: %s\n" % (key_full_text, str(scheme), stu_full_text)
<     ## TEST: from tests import *
<     ## TEST: at = AlgorithmTest()
<     ## TEST: rulelist = at._updaterulelist(scheme, pointlist)
<     text_pointlist = [point['Point_No'] for point in pointlist if 'P0.' not in point['Point_No']]
<     ms = MarkScheme(text_pointlist)
<     rulelist = [r for r in ms.GetRules(scheme)]
<     #
<     mark, marklist, omitted = ans.Analysis(stu_full_text_proper, key_freq_dist, key_sentencelist, pointlist, rulelist)
<     print "Result:\n\nMark: %s\nList: %s\nOmitted: %s" % (str(mark), str(marklist), str(omitted))
<     debug_print("stop algo/answer.py: " + debug_timestamp())
------------------------------------------------------------------------

answer.py.old vs. ../old-algo/answer.py.old
diff: ../old-algo/answer.py.old: No such file or directory
diff: ../old-algo/answer.py.old: No such file or directory
------------------------------------------------------------------------

answer.py.test vs. ../old-algo/answer.py.test
diff: ../old-algo/answer.py.test: No such file or directory
diff: ../old-algo/answer.py.test: No such file or directory
------------------------------------------------------------------------

canvascompare.py vs. ../old-algo/canvascompare.py
------------------------------------------------------------------------

common.py vs. ../old-algo/common.py
------------------------------------------------------------------------

common.pyo vs. ../old-algo/common.pyo
diff: ../old-algo/common.pyo: No such file or directory
diff: ../old-algo/common.pyo: No such file or directory
------------------------------------------------------------------------

markscheme.py vs. ../old-algo/markscheme.py
Differences: markscheme.py ../old-algo/markscheme.py
-rwxr-xr-x 1 tomohara None 2966 Dec 13 17:14 markscheme.py
-rw-r--r-- 1 tomohara None 618 Sep 16 18:25 ../old-algo/markscheme.py
1,12c1
< #! /usr/bin/python
< #
< # markscheme.py: Defines simple class for accessing rules produced when parsing
< # marking schemes via MarkingSchemeLang (see scheme_lang.py).
< # Warning: *** This is not used anywhere except for tests.py. ***
< # TODO: Make MarkScheme a class embedded in tests.py (to avoid confusion)???
< #
< 
< # Local packages
< #
< from common import *
< debug_print("algo/markscheme.py: " + debug_timestamp())
---
> import logging
15,17d3
< # Other packages
< #
< import logging
21,22d6
<     # constructor: initializes instance using given list of question/point names
<     # EX: ms = MarkScheme(['P1.1', 'P1.2', 'P2', 'P3', 'P4'])
24d7
<         debug_print("MarkScheme(%s)" % str(plist), level=5)
26c9
<         self.msl = MarkingSchemeLang(plist)
---
>         self.sc = MarkingSchemeLang(plist)
29d11
<     ## TODO: remove following unused method 
37,39d18
<     # GetRules(MARKED_GRADING_SPECS): Parses each of the grading specifications
<     # with associated grade in MARKED_GRADING_SPECS, returning list with 
<     # EX: list(ms.GetRules([("all less P4", 75), ("only P1.1", 10)])) => [{'Mark': 75, 'Point': ['P2', 'P1.2', 'P1.1', 'P3']}, {'Mark': 10, 'Point': ['P1.1']}]
41d19
<         debug_print("in GetRules(%s)" % str(templates), level=5)
43c21
<             rlist = self.msl.analysis(rule, int(mark))
---
>             rlist = self.sc.analysis(rule, int(mark))
45,46d22
<                 rule_hash = {'Point': rule, 'Mark': score}
<                 debug_print("yielding %s\n" % str(rule_hash), level=5)
48,88d23
<         debug_print("out GetRules()", level=5)
< 
< # Run simple example if invoked from command line
< #
< if __name__ == "__main__":
<     debug_print("start: " + debug_timestamp())
<     #
<     print "Simple example"
<     print
< 
<     # Initialize simple rule scheme spcification and display
<     points = ['P7', 'P2', 'P13']
<     templates = [("all", 100), 
<                  ("any two combinations of P7 ; P2 ; P13", 67.7),
<                  ("only P7 or P2 or P13", 33.3),
<                  ("none", 0)]
<     print "Input:"
<     print "\tpoints: %s" % points
<     print
<     print "\ttemplates:\n\t%s\n" % "\n\t".join([str(t) for t in templates])
<     print
< 
<     # Run through scheme parser
<     # Note: generator output expanded here to traps exceptions
<     #
<     print "Output:"
<     try:
<         ms = MarkScheme(points)
<         rules = [r for r in ms.GetRules(templates)]
<     except:
<         if __debug__:
<             raise
<         rules = None
<         print_stderr("Exception processing sentence:\n\t%s" % str(sys.exc_info()))
< 
<     # Show result
<     #
<     for rule_hash in rules:
<         for key in rule_hash.keys():
<             print "%s: %s" % (key, rule_hash[key]),
<         print
------------------------------------------------------------------------

scheme_lang.py vs. ../old-algo/scheme_lang.py
Differences: scheme_lang.py ../old-algo/scheme_lang.py
-rwxr-xr-x 1 tomohara None 18885 Dec 13 05:41 scheme_lang.py
-rwxr-xr-x 1 tomohara None 15688 Dec 13 22:22 ../old-algo/scheme_lang.py
3,8c3
< # scheme_lang.py: defines MarkingSchemeLang class for parsing the grading key marking scheme.
< # Note: includes simple usage example when run standalone.
< #
< # TODO: Cut down on excessive use of generators as efficiency is memory overhead
< # is not an issue with the parser. This needlessly makes the code hard to maintain:
< # the logic is harder to follow, and the code is harder to debug.
---
> # scheme_lang.py: defines class for parsing the testing key marking scheme
208c203
<                 debug_print("p:%s,ops:%s" % (p, ops), level=5)
---
>                 debug_print("p:%s,ops:%s" % (p, ops), level=4)
264c259
<                 debug_print("NUM:%d, List:%s, ops:%s" % (self.phraseAnyNumArray[i], self.phrasePointlistArray[i], self.anyOpsArray[i]), level=6)
---
>                 debug_print("NUM:%d, List:%s, ops:%s" % (self.phraseAnyNumArray[i], self.phrasePointlistArray[i], self.anyOpsArray[i]), level=4)
275c270
<                     debug_print("NUM:%d, List:%s" % (usefulNum, str(usefulArray)), level=6)
---
>                     debug_print("NUM:%d, List:%s" % (usefulNum, str(usefulArray)), level=4)
277c272
<                 debug_print("usefulArray=%s, usefulNum=%d" % (str(usefulArray), usefulNum), level=6)
---
>                 debug_print("usefulArray=%s, usefulNum=%d" % (str(usefulArray), usefulNum), level=4)
281c276
<                 debug_print("phrasecombs:%s, len:%d" % (phrasecombs, len(phrasecombs)), level=6)
---
>                 debug_print("phrasecombs:%s, len:%d" % (phrasecombs, len(phrasecombs)), level=4)
306c301
<                 debug_print("NUM:%d, List:%s, ops:%s" % (self.phraseAnyNumArray[i], self.phrasePointlistArray[i], self.anyOpsArray[i]), level=6)
---
>                 debug_print("NUM:%d, List:%s, ops:%s" % (self.phraseAnyNumArray[i], self.phrasePointlistArray[i], self.anyOpsArray[i]), level=4)
317c312
<                 debug_print("usefulArray=%s, usefulNum=%d" % (str(usefulArray), usefulNum), level=6)
---
>                 debug_print("usefulArray=%s, usefulNum=%d" % (str(usefulArray), usefulNum), level=4)
322c317
<                 debug_print("phrasecombs:%s, len:%d" % (phrasecombs, len(phrasecombs)), level=6)
---
>                 debug_print("phrasecombs:%s, len:%d" % (phrasecombs, len(phrasecombs)), level=4)
340,342d334
<     # MarkingSchemeLang(point_list): Initialize for marking question names in POINT_LIST.
<     # EX: msl = MarkingSchemeLang(['P1.1', 'P1.2', 'P2', 'P3', 'P4'])
<     #
349,353d340
<     # analysis(GRADING_SPEC, SCORE): Generator for converting GRADING_SPEC into sequence of
<     # rules having the associated SCORE. If valid each item is a tuple with rule text and score value,
<     # otherwise, None is generated.
<     # EX: [r for r in msl.analysis("all less P4", 75.5)] => [(['P2', 'P1.2', 'P1.1', 'P3'], 75.5)]
<     #
355c342
<         debug_print("in MarkingSchemeLang:analysis(\"%s\", %d)" % (sent, mark), level=4)
---
>         debug_print("MarkingSchemeLang:analysis(\"%s\", %d)" % (sent, mark), level=4)
363c350
<             debug_print("lexical analysis:", level=5)
---
>             debug_print("lexical analysis: ")
367,369c354,355
<                 if not tok: 
<                     break
<                 debug_print("tok=%s" % tok, level=6)
---
>                 if not tok: break
>                 debug_print("tok=%s" % tok, level=4)
371c357
<         debug_print("parsing sent:", level=5)
---
>         debug_print("parsing sent", level=3)
375d360
<                 debug_print("MarkingSchemeLang:analysis() yeilds %s" % str((rule, mark)), level=4)
378d362
<             debug_print("MarkingSchemeLang:analysis() yeilds None", level=4)
380,411d363
<         debug_print("out MarkingSchemeLang:analysis()", level=4)
< 
< 
< # show_simple_example(): Runs a simple example of
< #
< def show_simple_example():
<     # Test running example from comments above
<     # TODO: Do this via unit testing framework (Python or Django)
<     if __debug__:
<         points = ['P1.1', 'P1.2', 'P2', 'P3', 'P4']
<         spec = "all less P4"
<         mark = 75.5
<         debug_print("points=%s spec='%s' mark=%f" % (points, spec, mark))
<         msl = MarkingSchemeLang(points)
<         result = [r for r in msl.analysis(spec, mark)]
<         debug_print("result: %s" % str(result))
<     
<     # Create the example specification
<     print "Simple example"
<     print
<     points = ['P1.1', 'P1.2', 'P2', 'P3', 'P4']
<     spec = "all less 2 combinations of P2;P3;P4"
<     mark = 70
<     print "Points: %s" % str(points)
<     print "Spec: %s" % spec
<     print "Mark: %d" % mark
< 
<     # Analyze the specification and display the expanded rules
<     msl = MarkingSchemeLang(points)
<     for (rule, score) in msl.analysis(spec, mark):
<         print "Rule: %s; Score: %d" % (rule, score)
<     print
417,423d368
< 
<     # First show simple example if debugging (for tracing purposes)
<     if __debug__:
<         show_simple_example()
< 
<     # Initialize the grading scheme parsing
<     print "Test set"
429d373
<     # Note: Negative tests must come first
437d380
<     num_neg_tests = len(data)
447,448c390,391
<     data += [("any 2 combinations of P1;P3 ; P5 ;P99; P7 and any 1 combinations of P4;P6 and any 3 combinations of P2;P3.24", 1)]	# TODO: make negative
<     data += [("less 2 combinations of P1;P3 ; P5 ;P99; P7 and less 1 combinations of P4;P6 and less 3 combinations of P2;P3.24", 1)]	# TODO: make negative
---
>     data += [("any 2 combinations of P1;P3 ; P5 ;P99; P7 and any 1 combinations of P4;P6 and any 3 combinations of P2;P3.24", 1)]
>     data += [("less 2 combinations of P1;P3 ; P5 ;P99; P7 and less 1 combinations of P4;P6 and less 3 combinations of P2;P3.24", 1)]
450c393
<     data += [("all less -1 combinations of P1;P3;P5;P9", 1)]   # TODO: make negative
---
>     data += [("all less -1 combinations of P1;P3;P5;P9", 1)]
455,456d397
<     num_good = 0
<     test_num = 0
458,462c399
<         # Try to parse the grading scheme and point specification.
<         # Note: generator output expanded here to encapsulate exceptions.
<         negative_test = (test_num < num_neg_tests)
<         test_num += 1
<         print "Test:%d Sent:'%s' | Score:%d | Negative:%s" % (test_num, sent, score, negative_test)
---
>         print "Sent:%s | Score:%d" % (sent, score)
464,488c401,411
<             rlist = [tuple for tuple in sc.analysis(sent, score) if tuple]
<         except:
<             rlist = None
<             if (negative_test or (debugging_level() > 3)):
<                 print_stderr("Exception processing sentence:\n\t%s" % str(sys.exc_info()))
< 
<         # See if test worked as expected
<         negative_result = (not rlist)
<         if (negative_test == negative_result):
<             num_good += 1
<         else:
<             print_stderr("Error: *** Unexpected test result")
< 
<         # Display the result
<         debug_print("rlist: %s" % str(rlist))
<         if negative_result:
<             print "This sentence cannot fit grammar"
<             print "--------------------------\n"
<             continue
<         for rule, score in rlist:
<             print "Rule:%s | Score:%d" % (rule, score)
<             print "--------------------------\n"
< 
<     # Print summary
<     print "%d of %d rules processed as expected" % (num_good, len(data))
---
>             rlist = sc.analysis(sent, score)
>             debug_print("rlist: %s" % str(rlist))
>             if not rlist:
>                 print "This sentence cannot fit grammar"
>                 print "--------------------------\n"
>                 continue
>             for rule, score in rlist:
>                 print "Rule:%s | Score:%d" % (rule, score)
>                 print "--------------------------\n"
> 	except:
>             print_stderr("Exception processing sentence:\n\t%s" % str(sys.exc_info()))
491c414
<     debug_print("stop: " + debug_timestamp(), level=2)
---
>     debug_print("stop: " + debug_timestamp())
------------------------------------------------------------------------

standard.py vs. ../old-algo/standard.py
Differences: standard.py ../old-algo/standard.py
-rwxr-xr-x 1 tomohara None 10854 Dec 13 20:38 standard.py
-rwxr-xr-x 1 tomohara None 9248 Dec 13 22:23 ../old-algo/standard.py
6,7d5
< # Local packages
< #
10d7
< import wordnet
12,13d8
< # Other packages
< #
26,29d20
<         # TODO: self.use_part_of_speech = [setting.USE_PART_OF_SPEECH]
<         self.use_part_of_speech = False
<         if __debug__:
<             self.use_part_of_speech = getenv_boolean("USE_PART_OF_SPEECH")
31d21
<         # TODO: use re.MULTILINE
38d27
<     # The result is returned as a list of hashes with with Point_No and Point_Text keys.
59,60d47
<     # Both the input ia a list of hashes, as is the result.
<     #
67d53
<         debug_print("Standard.SentenceAnalysis(%s)" % str(pointlist), level=7)
88c74
<         debug_print("Standard.SentenceAnalysis() => %s" % str(sentencelist), level=5)
---
>         debug_print("Standard.SentenceAnalysis(%s) => %s" % (str(pointlist), str(sentencelist)), level=5)
93d78
<     #
112c97
<     #
---
>     # EX: TODO
116c101
<         debug_print("Standard.CalVector(%s)" % sentencelist, level=5)
---
>         debug_print("Standard.CalVector(_)", level=5)
123c108
<             # OLD: #word.lower() + '/' + tag
---
>             #word.lower() + '/' + tag
128,133d112
<             words_proper = list(word for word in words if word)
<             if self.use_part_of_speech:
<                 # Prefix each word with wordnet part-of-speech indicator (e.g., ['fast', 'car'] => ['a:fast', 'n:car'])
<                 words_proper = [(wordnet.get_part_of_speech(tag) + ":" + word) 
<                                 for (word, (token, tag)) in zip(words, part_of_speech_tagged_words) 
<                                 if word],
135c114
<             sentence['SenWords'] = words_proper
---
>             sentence['SenWords'] = list(word for word in words if word)
145,146c124
<     # Note: Changes made here should be synchronized with SentenceAnalysis in answer.py.
<     #
---
>     # Note: Changes should be synchronized with SentenceAnalysis in answer.py.
151c129
<         debug_print("Standard.SentenceCal%s" % str((sentencelist, textfdist)), level=5)
---
>         debug_print("Standard.SentenceCal(_)", level=5)
171d148
<     #
173d149
<     # TODO: flesh out _
176c152
<         debug_print("Standard.Analysis(%s)" % fulltext, level=99)
---
>         debug_print("Standard.Analysis(_)", level=5)
183,192d158
< 
< # If invoked standalone, show analysis of simple hard-coded example (see tests.py for detailed examples).
< #
< if __name__ == '__main__':
<     full_text = "1 . It captured the vibrancy of India's slums.\n2 . which are often misperceived as being simply rundown housing areas.\n"
<     print "Input:\n\n%s\n" % full_text
<     std = Standard()
<     (pointlist, textfdist, slist) = std.Analysis(full_text)
<     print "Output: \n\nPoints: %s\nDist: %s\nSents: %s\n" % (str(pointlist), str(textfdist), str(slist))
<     debug_print("stop algo/standard.py: " + debug_timestamp())
------------------------------------------------------------------------

test-settings.py vs. ../old-algo/test-settings.py
diff: ../old-algo/test-settings.py: No such file or directory
diff: ../old-algo/test-settings.py: No such file or directory
------------------------------------------------------------------------

tests.py vs. ../old-algo/tests.py
Differences: tests.py ../old-algo/tests.py
-rwxr-xr-x 1 tomohara None 22586 Dec 13 21:47 tests.py
-rwxr-xr-x 1 tomohara None 21639 Dec 13 22:10 ../old-algo/tests.py
193c193
< ## OLD: #@unittest.skip("Too much time")
---
> #@unittest.skip("Too much time")
198,200d197
<         self.exclude_long_tests = False
<         if __debug__:
<             self.exclude_long_tests = getenv_boolean("EXCLUDE_LONG_TESTS")
202c199
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
205,207d201
<         if __debug__ and self.exclude_long_tests:
<             debug_print("Excluding lengthy test: " + current_function_name())
<             return
226c220
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
231,234d224
<         if __debug__ and self.exclude_long_tests:
<             debug_print("Excluding lengthy test: " + current_function_name())
<             return
< 
266c256
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
269,272d258
<         if __debug__ and self.exclude_long_tests:
<             debug_print("Excluding lengthy test: " + current_function_name())
<             return
< 
374c360
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
376,378d361
<         if __debug__ and self.exclude_long_tests:
<             debug_print("Excluding lengthy test: " + current_function_name())
<             return
390c373
<     ## OLD: #@unittest.skip("Too much time")
---
>     #@unittest.skip("Too much time")
392,394d374
<         if __debug__ and self.exclude_long_tests:
<             debug_print("Excluding lengthy test: " + current_function_name())
<             return
478c458
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
482c462
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
486c466
<     ## OLD: @unittest.skip("Too much time")
---
>     @unittest.skip("Too much time")
499c479
< debug_print("stop algo/tests.py: " + debug_timestamp())
---
> debug_print("algo/tests.py end: " + debug_timestamp())
------------------------------------------------------------------------

text.py vs. ../old-algo/text.py
diff: ../old-algo/text.py: No such file or directory
diff: ../old-algo/text.py: No such file or directory
------------------------------------------------------------------------

wordnet.py vs. ../old-algo/wordnet.py
diff: ../old-algo/wordnet.py: No such file or directory
diff: ../old-algo/wordnet.py: No such file or directory
------------------------------------------------------------------------

